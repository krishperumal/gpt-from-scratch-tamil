{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d3bBBPnDSPJ",
        "outputId": "c051abe3-8423-4c90-f1f1-b3a2aa44211c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "vocab_size=130\n",
            "chars=['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '£', '©', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', '்', '௦', '௧', '௩', '௫', '௬', '௱', '—', '‘', '“', '”']\n",
            "encoded_text=[105, 93, 87, 119, 87, 98, 119, 10, 1, 82, 97, 119, 97, 92, 110, 1, 78, 100, 112, 87, 119, 87, 110, 101, 111, 100, 119, 87, 103, 119, 28]\n",
            "decoded_text='வணக்கம், எப்படி இருக்கிறீர்கள்?'\n",
            "len(train)=3751152\n",
            "len(val)=416795\n"
          ]
        }
      ],
      "source": [
        "# Read input data\n",
        "# Only for the first time - Download ponniyin selvan text as html\n",
        "# !wget -O ponniyin-selvan.html https://archive.org/stream/PonniyinSelvan/Ponniyin-Selvan_djvu.txt\n",
        "\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# import shutil\n",
        "# shutil.copy('ponniyin-selvan.html', '/content/drive/MyDrive/Colab Notebooks/data')\n",
        "# Extract text from html file if it doesn't exist\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "html_file_name = '/content/drive/MyDrive/Colab Notebooks/data/ponniyin-selvan.html'\n",
        "text_file_name = '/content/drive/MyDrive/Colab Notebooks/data/ponniyin-selvan.txt'\n",
        "if not os.path.exists(text_file_name):\n",
        "\n",
        "  # Read the content of the downloaded file\n",
        "  with open(html_file_name, 'r') as f:\n",
        "    html_content = f.read()\n",
        "\n",
        "  # Parse the HTML content\n",
        "  soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "  # Find the element with id=\"maincontent\"\n",
        "  main_content = soup.find('main', id='maincontent').find('pre')\n",
        "\n",
        "  # Print the extracted content\n",
        "  if main_content:\n",
        "    with open(text_file_name, 'w', encoding='utf-8', errors='ignore') as f:\n",
        "      f.write(main_content.get_text())\n",
        "    print(f\"Full text written to {text_file_name}\")\n",
        "  else:\n",
        "    print(\"Element with id='maincontent' not found.\")\n",
        "\n",
        "# read full file text\n",
        "with open(text_file_name, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "  input_text = f.read()\n",
        "  # clean up text\n",
        "  input_text = re.sub(r'\\u200c|Table of Contents', '', input_text).strip()\n",
        "\n",
        "# Get Vocabulary\n",
        "chars = sorted(list(set(input_text)))\n",
        "vocab_size = len(chars)\n",
        "print(f\"{vocab_size=}\")\n",
        "print(f\"{chars=}\")\n",
        "\n",
        "# Use character encodings\n",
        "stoi = { s:i for (i,s) in enumerate(chars)}\n",
        "itos = { i:s for (i,s) in enumerate(chars)}\n",
        "\n",
        "encode = lambda txt: [stoi[s] for s in txt]\n",
        "decode = lambda enc: ''.join([itos[i] for i in enc])\n",
        "\n",
        "encoded_text = encode('வணக்கம், எப்படி இருக்கிறீர்கள்?')\n",
        "print(f\"{encoded_text=}\")\n",
        "decoded_text = decode(encoded_text)\n",
        "print(f\"{decoded_text=}\")\n",
        "\n",
        "# train and val split\n",
        "import torch\n",
        "split_idx = int(0.9*len(input_text))\n",
        "train = torch.tensor(encode(input_text[:split_idx]))\n",
        "val = torch.tensor(encode(input_text[split_idx:]))\n",
        "print(f\"{len(train)=}\")\n",
        "print(f\"{len(val)=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jM7VCrnDDkR0"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# seed for reproducibility\n",
        "torch.manual_seed(9871)\n",
        "\n",
        "# Hyperparameters\n",
        "block_size = 256\n",
        "batch_size = 64\n",
        "embedding_dim = 384\n",
        "head_size = 64\n",
        "num_heads = 6\n",
        "num_decoder_layers = 6\n",
        "dropout = 0.2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NsU8vGXMERre"
      },
      "outputs": [],
      "source": [
        "def get_batch(split):\n",
        "  if split == 'train':\n",
        "    data = train\n",
        "  else:\n",
        "    data = val\n",
        "\n",
        "  # get random batch indexes\n",
        "  idxs = torch.randint(0, data.size(0)-block_size, (batch_size,))\n",
        "  x = torch.stack([data[idx:idx+block_size] for idx in idxs])\n",
        "  y = torch.stack([data[idx+1:idx+block_size+1] for idx in idxs])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2TkIN9eFp5k",
        "outputId": "a214060d-2cc0-4d1d-97b5-bdd066f619ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits=tensor([[-0.2943,  0.5052,  0.0071,  ..., -0.6274,  0.4139,  0.3725],\n",
            "        [ 0.7575, -0.0063,  1.2228,  ..., -1.0606,  0.0549,  1.0124],\n",
            "        [ 0.1860,  0.6670,  0.5804,  ...,  0.8386, -0.2030, -0.7848],\n",
            "        ...,\n",
            "        [ 0.6456, -0.9637,  1.1226,  ..., -0.2760, -0.2926,  1.0233],\n",
            "        [-1.0074,  1.6333,  0.0067,  ..., -1.3264,  1.0185, -0.1407],\n",
            "        [ 0.1065,  0.5943, -1.0157,  ..., -1.1597,  0.2001,  0.8837]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "loss=tensor(4.9599, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(embedding_dim, head_size, bias=False)\n",
        "    self.query = nn.Linear(embedding_dim, head_size, bias=False)\n",
        "    self.value = nn.Linear(embedding_dim, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones((block_size, block_size))))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # we require T for initializing generation from potentially less than\n",
        "    # block size number of tokens as input\n",
        "    _, T, _ = x.shape\n",
        "    q = self.key(x)\n",
        "    k = self.query(x)\n",
        "    v = self.value(x)\n",
        "    weights = q @ k.transpose(-2, -1) * head_size**-2\n",
        "    weights = weights.masked_fill(self.tril[:T,:T] == 0, float('-inf'))\n",
        "    weights = F.softmax(weights, dim=-1)\n",
        "    weights = self.dropout(weights)\n",
        "    output = weights @ v\n",
        "    return output\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.attention_heads = nn.ModuleList([\n",
        "        AttentionBlock() for _ in range(num_heads)\n",
        "    ])\n",
        "    self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    att = torch.cat([att(x) for att in self.attention_heads], dim=-1)\n",
        "    lin = self.linear(att)\n",
        "    out = self.dropout(lin)\n",
        "    return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ffwd = nn.Sequential(\n",
        "      nn.Linear(embedding_dim, embedding_dim*4),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(embedding_dim*4, embedding_dim),\n",
        "      nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.ffwd(x)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.multi_head_attention = MultiHeadAttention()\n",
        "    self.feed_forward = FeedForward()\n",
        "    self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
        "    self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    att = self.multi_head_attention(x)\n",
        "    att_addnorm = self.layer_norm1(x + att)\n",
        "    ffwd = self.feed_forward(att)\n",
        "    ffwd_addnorm = self.layer_norm2(x + ffwd)\n",
        "    return ffwd_addnorm\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding = nn.Embedding(\n",
        "        num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "    self.pos_embedding = nn.Embedding(\n",
        "        num_embeddings=block_size, embedding_dim=embedding_dim)\n",
        "    self.decoder_blocks = nn.Sequential(*[DecoderBlock()\n",
        "        for _ in range(num_decoder_layers)])\n",
        "    self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, x, y=None):\n",
        "    # assuming that only last block_size elements are sent as input\n",
        "    B, T = x.shape\n",
        "    emb = self.token_embedding(x) + self.pos_embedding(torch.arange(T, device=device))\n",
        "    decoded = self.decoder_blocks(emb)\n",
        "    logits = self.linear(decoded)\n",
        "\n",
        "    if y is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      y = y.view(B*T)\n",
        "      loss = F.cross_entropy(logits, y)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, x, max_num_steps=1000):\n",
        "    for _ in range(max_num_steps):\n",
        "      logits, _ = self(x[:, :block_size])\n",
        "      logits = logits[:, -1, :]\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "      x_next = torch.multinomial(probs, num_samples=1)\n",
        "      x = torch.cat((x, x_next), dim=1)\n",
        "    return x\n",
        "\n",
        "# test forward with random batch\n",
        "xb, yb = get_batch('train')\n",
        "model = Transformer()\n",
        "model = model.to(device)\n",
        "logits, loss = model(xb, yb)\n",
        "print(f\"{logits=}\")\n",
        "print(f\"{loss=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "USnrdp3qerN-",
        "outputId": "4e285d4f-0743-44bb-ab1e-b928cd62c6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 3.911228656768799 at i=10\n",
            "Validation 3.353227138519287 at i=10\n",
            "Train 3.327735424041748 at i=20\n",
            "Validation 3.252861499786377 at i=20\n",
            "Train 3.2576687335968018 at i=30\n",
            "Validation 3.191645383834839 at i=30\n",
            "Train 3.1933419704437256 at i=40\n",
            "Validation 3.1416923999786377 at i=40\n",
            "Train 3.119558811187744 at i=50\n",
            "Validation 3.0508320331573486 at i=50\n",
            "Train 3.0286049842834473 at i=60\n",
            "Validation 2.9590065479278564 at i=60\n",
            "Train 2.9308998584747314 at i=70\n",
            "Validation 2.8596253395080566 at i=70\n",
            "Train 2.830681085586548 at i=80\n",
            "Validation 2.7513113021850586 at i=80\n",
            "Train 2.711406946182251 at i=90\n",
            "Validation 2.600435256958008 at i=90\n",
            "Train 2.6131932735443115 at i=100\n",
            "Validation 2.5224454402923584 at i=100\n",
            "Train 2.5317957401275635 at i=110\n",
            "Validation 2.472311496734619 at i=110\n",
            "Train 2.48185133934021 at i=120\n",
            "Validation 2.4379794597625732 at i=120\n",
            "Train 2.4541945457458496 at i=130\n",
            "Validation 2.4246339797973633 at i=130\n",
            "Train 2.4245824813842773 at i=140\n",
            "Validation 2.403795003890991 at i=140\n",
            "Train 2.412393093109131 at i=150\n",
            "Validation 2.392930030822754 at i=150\n",
            "Train 2.3849716186523438 at i=160\n",
            "Validation 2.3580563068389893 at i=160\n",
            "Train 2.384054660797119 at i=170\n",
            "Validation 2.3530478477478027 at i=170\n",
            "Train 2.3728585243225098 at i=180\n",
            "Validation 2.346506118774414 at i=180\n",
            "Train 2.360438585281372 at i=190\n",
            "Validation 2.33811092376709 at i=190\n",
            "Train 2.3478572368621826 at i=200\n",
            "Validation 2.338855743408203 at i=200\n",
            "Train 2.3472392559051514 at i=210\n",
            "Validation 2.3166608810424805 at i=210\n",
            "Train 2.3500277996063232 at i=220\n",
            "Validation 2.3155956268310547 at i=220\n",
            "Train 2.3358654975891113 at i=230\n",
            "Validation 2.3150856494903564 at i=230\n",
            "Train 2.3208417892456055 at i=240\n",
            "Validation 2.321967601776123 at i=240\n",
            "Train 2.324580430984497 at i=250\n",
            "Validation 2.305450916290283 at i=250\n",
            "Train 2.3180959224700928 at i=260\n",
            "Validation 2.3013081550598145 at i=260\n",
            "Train 2.315838575363159 at i=270\n",
            "Validation 2.302626848220825 at i=270\n",
            "Train 2.3069658279418945 at i=280\n",
            "Validation 2.2992124557495117 at i=280\n",
            "Train 2.314404249191284 at i=290\n",
            "Validation 2.2809901237487793 at i=290\n",
            "Train 2.3147168159484863 at i=300\n",
            "Validation 2.293997049331665 at i=300\n",
            "Train 2.3059210777282715 at i=310\n",
            "Validation 2.2684547901153564 at i=310\n",
            "Train 2.3026719093322754 at i=320\n",
            "Validation 2.2654035091400146 at i=320\n",
            "Train 2.30183482170105 at i=330\n",
            "Validation 2.275918483734131 at i=330\n",
            "Train 2.2932536602020264 at i=340\n",
            "Validation 2.2786483764648438 at i=340\n",
            "Train 2.2869646549224854 at i=350\n",
            "Validation 2.2612433433532715 at i=350\n",
            "Train 2.2950279712677 at i=360\n",
            "Validation 2.261009931564331 at i=360\n",
            "Train 2.2804856300354004 at i=370\n",
            "Validation 2.2695131301879883 at i=370\n",
            "Train 2.2793021202087402 at i=380\n",
            "Validation 2.2806975841522217 at i=380\n",
            "Train 2.280135154724121 at i=390\n",
            "Validation 2.2806382179260254 at i=390\n",
            "Train 2.2705559730529785 at i=400\n",
            "Validation 2.2452611923217773 at i=400\n",
            "Train 2.279086112976074 at i=410\n",
            "Validation 2.2595667839050293 at i=410\n",
            "Train 2.272516965866089 at i=420\n",
            "Validation 2.250913619995117 at i=420\n",
            "Train 2.2684760093688965 at i=430\n",
            "Validation 2.2387821674346924 at i=430\n",
            "Train 2.2665443420410156 at i=440\n",
            "Validation 2.2385857105255127 at i=440\n",
            "Train 2.2627651691436768 at i=450\n",
            "Validation 2.2437808513641357 at i=450\n",
            "Train 2.2561631202697754 at i=460\n",
            "Validation 2.2479448318481445 at i=460\n",
            "Train 2.2543396949768066 at i=470\n",
            "Validation 2.2474794387817383 at i=470\n",
            "Train 2.2522175312042236 at i=480\n",
            "Validation 2.249605178833008 at i=480\n",
            "Train 2.2499465942382812 at i=490\n",
            "Validation 2.253164768218994 at i=490\n",
            "Train 2.247641086578369 at i=500\n",
            "Validation 2.221761703491211 at i=500\n",
            "Train 2.2520384788513184 at i=510\n",
            "Validation 2.2197165489196777 at i=510\n",
            "Train 2.2501718997955322 at i=520\n",
            "Validation 2.231255531311035 at i=520\n",
            "Train 2.249189853668213 at i=530\n",
            "Validation 2.23134183883667 at i=530\n",
            "Train 2.2398488521575928 at i=540\n",
            "Validation 2.229902744293213 at i=540\n",
            "Train 2.2427687644958496 at i=550\n",
            "Validation 2.2345705032348633 at i=550\n",
            "Train 2.2334036827087402 at i=560\n",
            "Validation 2.2116639614105225 at i=560\n",
            "Train 2.2274792194366455 at i=570\n",
            "Validation 2.215453624725342 at i=570\n",
            "Train 2.2340521812438965 at i=580\n",
            "Validation 2.2098190784454346 at i=580\n",
            "Train 2.2379403114318848 at i=590\n",
            "Validation 2.1986966133117676 at i=590\n",
            "Train 2.2293896675109863 at i=600\n",
            "Validation 2.2173211574554443 at i=600\n",
            "Train 2.2279722690582275 at i=610\n",
            "Validation 2.227019786834717 at i=610\n",
            "Train 2.2281322479248047 at i=620\n",
            "Validation 2.219618797302246 at i=620\n",
            "Train 2.228830099105835 at i=630\n",
            "Validation 2.1942577362060547 at i=630\n",
            "Train 2.222289562225342 at i=640\n",
            "Validation 2.209925413131714 at i=640\n",
            "Train 2.228445053100586 at i=650\n",
            "Validation 2.2256550788879395 at i=650\n",
            "Train 2.2179207801818848 at i=660\n",
            "Validation 2.20235013961792 at i=660\n",
            "Train 2.2203664779663086 at i=670\n",
            "Validation 2.199061870574951 at i=670\n",
            "Train 2.220447063446045 at i=680\n",
            "Validation 2.1916961669921875 at i=680\n",
            "Train 2.212761163711548 at i=690\n",
            "Validation 2.198843002319336 at i=690\n",
            "Train 2.2113943099975586 at i=700\n",
            "Validation 2.1831395626068115 at i=700\n",
            "Train 2.219041109085083 at i=710\n",
            "Validation 2.1995747089385986 at i=710\n",
            "Train 2.216585636138916 at i=720\n",
            "Validation 2.192937135696411 at i=720\n",
            "Train 2.2122116088867188 at i=730\n",
            "Validation 2.1953694820404053 at i=730\n",
            "Train 2.2022805213928223 at i=740\n",
            "Validation 2.206655740737915 at i=740\n",
            "Train 2.2037880420684814 at i=750\n",
            "Validation 2.1739931106567383 at i=750\n",
            "Train 2.199789524078369 at i=760\n",
            "Validation 2.189319372177124 at i=760\n",
            "Train 2.2010488510131836 at i=770\n",
            "Validation 2.167337417602539 at i=770\n",
            "Train 2.2010066509246826 at i=780\n",
            "Validation 2.185781478881836 at i=780\n",
            "Train 2.2004079818725586 at i=790\n",
            "Validation 2.181474208831787 at i=790\n",
            "Train 2.1967475414276123 at i=800\n",
            "Validation 2.182229518890381 at i=800\n",
            "Train 2.1952106952667236 at i=810\n",
            "Validation 2.153409004211426 at i=810\n",
            "Train 2.181776762008667 at i=820\n",
            "Validation 2.1644551753997803 at i=820\n",
            "Train 2.1939849853515625 at i=830\n",
            "Validation 2.16066575050354 at i=830\n",
            "Train 2.193599224090576 at i=840\n",
            "Validation 2.158656597137451 at i=840\n",
            "Train 2.1877548694610596 at i=850\n",
            "Validation 2.171708345413208 at i=850\n",
            "Train 2.183696746826172 at i=860\n",
            "Validation 2.152791738510132 at i=860\n",
            "Train 2.185361862182617 at i=870\n",
            "Validation 2.1718735694885254 at i=870\n",
            "Train 2.1853184700012207 at i=880\n",
            "Validation 2.1650311946868896 at i=880\n",
            "Train 2.175478935241699 at i=890\n",
            "Validation 2.1589162349700928 at i=890\n",
            "Train 2.1865715980529785 at i=900\n",
            "Validation 2.164642810821533 at i=900\n",
            "Train 2.1779634952545166 at i=910\n",
            "Validation 2.169445514678955 at i=910\n",
            "Train 2.176933765411377 at i=920\n",
            "Validation 2.150636911392212 at i=920\n",
            "Train 2.1780261993408203 at i=930\n",
            "Validation 2.1374998092651367 at i=930\n",
            "Train 2.176582098007202 at i=940\n",
            "Validation 2.1455318927764893 at i=940\n",
            "Train 2.175283908843994 at i=950\n",
            "Validation 2.141387939453125 at i=950\n",
            "Train 2.1708192825317383 at i=960\n",
            "Validation 2.1545767784118652 at i=960\n",
            "Train 2.1707229614257812 at i=970\n",
            "Validation 2.1412980556488037 at i=970\n",
            "Train 2.1628901958465576 at i=980\n",
            "Validation 2.144347667694092 at i=980\n",
            "Train 2.1692557334899902 at i=990\n",
            "Validation 2.101801872253418 at i=990\n",
            "Train 2.1639227867126465 at i=1000\n",
            "Validation 2.130730628967285 at i=1000\n",
            "Train 2.1662373542785645 at i=1010\n",
            "Validation 2.119699716567993 at i=1010\n",
            "Train 2.157808780670166 at i=1020\n",
            "Validation 2.108754873275757 at i=1020\n",
            "Train 2.1618897914886475 at i=1030\n",
            "Validation 2.1237540245056152 at i=1030\n",
            "Train 2.163071393966675 at i=1040\n",
            "Validation 2.108147382736206 at i=1040\n",
            "Train 2.151668071746826 at i=1050\n",
            "Validation 2.1055965423583984 at i=1050\n",
            "Train 2.1468148231506348 at i=1060\n",
            "Validation 2.1205105781555176 at i=1060\n",
            "Train 2.140536069869995 at i=1070\n",
            "Validation 2.112764358520508 at i=1070\n",
            "Train 2.149705410003662 at i=1080\n",
            "Validation 2.104222059249878 at i=1080\n",
            "Train 2.1397759914398193 at i=1090\n",
            "Validation 2.099104404449463 at i=1090\n",
            "Train 2.1465888023376465 at i=1100\n",
            "Validation 2.1109232902526855 at i=1100\n",
            "Train 2.1415369510650635 at i=1110\n",
            "Validation 2.0922112464904785 at i=1110\n",
            "Train 2.13905668258667 at i=1120\n",
            "Validation 2.0988993644714355 at i=1120\n",
            "Train 2.1246700286865234 at i=1130\n",
            "Validation 2.0924034118652344 at i=1130\n",
            "Train 2.1325035095214844 at i=1140\n",
            "Validation 2.106884002685547 at i=1140\n",
            "Train 2.1251368522644043 at i=1150\n",
            "Validation 2.0819520950317383 at i=1150\n",
            "Train 2.1166024208068848 at i=1160\n",
            "Validation 2.071256399154663 at i=1160\n",
            "Train 2.1226255893707275 at i=1170\n",
            "Validation 2.0822105407714844 at i=1170\n",
            "Train 2.1137306690216064 at i=1180\n",
            "Validation 2.074878454208374 at i=1180\n",
            "Train 2.1101489067077637 at i=1190\n",
            "Validation 2.075853109359741 at i=1190\n",
            "Train 2.1092653274536133 at i=1200\n",
            "Validation 2.0586659908294678 at i=1200\n",
            "Train 2.1083967685699463 at i=1210\n",
            "Validation 2.028568983078003 at i=1210\n",
            "Train 2.1080660820007324 at i=1220\n",
            "Validation 2.0734243392944336 at i=1220\n",
            "Train 2.103764533996582 at i=1230\n",
            "Validation 2.0695230960845947 at i=1230\n",
            "Train 2.099689245223999 at i=1240\n",
            "Validation 2.053049087524414 at i=1240\n",
            "Train 2.09531569480896 at i=1250\n",
            "Validation 2.050229787826538 at i=1250\n",
            "Train 2.097501754760742 at i=1260\n",
            "Validation 2.0264220237731934 at i=1260\n",
            "Train 2.0857198238372803 at i=1270\n",
            "Validation 2.019230842590332 at i=1270\n",
            "Train 2.0864319801330566 at i=1280\n",
            "Validation 2.0355377197265625 at i=1280\n",
            "Train 2.082202672958374 at i=1290\n",
            "Validation 2.038560152053833 at i=1290\n",
            "Train 2.0852465629577637 at i=1300\n",
            "Validation 2.0044522285461426 at i=1300\n",
            "Train 2.074796438217163 at i=1310\n",
            "Validation 2.0466866493225098 at i=1310\n",
            "Train 2.076019763946533 at i=1320\n",
            "Validation 1.9957103729248047 at i=1320\n",
            "Train 2.064911365509033 at i=1330\n",
            "Validation 2.0065550804138184 at i=1330\n",
            "Train 2.0692238807678223 at i=1340\n",
            "Validation 2.0021066665649414 at i=1340\n",
            "Train 2.064866542816162 at i=1350\n",
            "Validation 1.9934978485107422 at i=1350\n",
            "Train 2.071525812149048 at i=1360\n",
            "Validation 1.9995054006576538 at i=1360\n",
            "Train 2.054931163787842 at i=1370\n",
            "Validation 1.9765369892120361 at i=1370\n",
            "Train 2.064905881881714 at i=1380\n",
            "Validation 1.9861832857131958 at i=1380\n",
            "Train 2.048238754272461 at i=1390\n",
            "Validation 1.9646565914154053 at i=1390\n",
            "Train 2.040377140045166 at i=1400\n",
            "Validation 1.9620723724365234 at i=1400\n",
            "Train 2.046234130859375 at i=1410\n",
            "Validation 1.9721367359161377 at i=1410\n",
            "Train 2.0503923892974854 at i=1420\n",
            "Validation 1.9586327075958252 at i=1420\n",
            "Train 2.0351109504699707 at i=1430\n",
            "Validation 1.9468772411346436 at i=1430\n",
            "Train 2.02742862701416 at i=1440\n",
            "Validation 1.9707465171813965 at i=1440\n",
            "Train 2.03105092048645 at i=1450\n",
            "Validation 1.9417908191680908 at i=1450\n",
            "Train 2.0210413932800293 at i=1460\n",
            "Validation 1.9324959516525269 at i=1460\n",
            "Train 2.021374225616455 at i=1470\n",
            "Validation 1.9457194805145264 at i=1470\n",
            "Train 2.026299476623535 at i=1480\n",
            "Validation 1.9686684608459473 at i=1480\n",
            "Train 2.01332426071167 at i=1490\n",
            "Validation 1.9254791736602783 at i=1490\n",
            "Train 2.006406784057617 at i=1500\n",
            "Validation 1.915781855583191 at i=1500\n",
            "Train 2.0047600269317627 at i=1510\n",
            "Validation 1.93505859375 at i=1510\n",
            "Train 2.000744104385376 at i=1520\n",
            "Validation 1.909287452697754 at i=1520\n",
            "Train 2.0106863975524902 at i=1530\n",
            "Validation 1.90504789352417 at i=1530\n",
            "Train 1.9953348636627197 at i=1540\n",
            "Validation 1.9031615257263184 at i=1540\n",
            "Train 1.9960371255874634 at i=1550\n",
            "Validation 1.9215325117111206 at i=1550\n",
            "Train 1.9813991785049438 at i=1560\n",
            "Validation 1.894453763961792 at i=1560\n",
            "Train 1.9800300598144531 at i=1570\n",
            "Validation 1.883557677268982 at i=1570\n",
            "Train 1.9866971969604492 at i=1580\n",
            "Validation 1.8839203119277954 at i=1580\n",
            "Train 1.9798446893692017 at i=1590\n",
            "Validation 1.8621916770935059 at i=1590\n",
            "Train 1.975834846496582 at i=1600\n",
            "Validation 1.897019624710083 at i=1600\n",
            "Train 1.9707167148590088 at i=1610\n",
            "Validation 1.8699250221252441 at i=1610\n",
            "Train 1.9643758535385132 at i=1620\n",
            "Validation 1.8591772317886353 at i=1620\n",
            "Train 1.9585835933685303 at i=1630\n",
            "Validation 1.8607487678527832 at i=1630\n",
            "Train 1.9524524211883545 at i=1640\n",
            "Validation 1.8346433639526367 at i=1640\n",
            "Train 1.9479684829711914 at i=1650\n",
            "Validation 1.8560616970062256 at i=1650\n",
            "Train 1.9483133554458618 at i=1660\n",
            "Validation 1.8467963933944702 at i=1660\n",
            "Train 1.9437024593353271 at i=1670\n",
            "Validation 1.833899736404419 at i=1670\n",
            "Train 1.9394747018814087 at i=1680\n",
            "Validation 1.8273488283157349 at i=1680\n",
            "Train 1.9296200275421143 at i=1690\n",
            "Validation 1.8064385652542114 at i=1690\n",
            "Train 1.9269177913665771 at i=1700\n",
            "Validation 1.8130451440811157 at i=1700\n",
            "Train 1.9310839176177979 at i=1710\n",
            "Validation 1.8041837215423584 at i=1710\n",
            "Train 1.9272692203521729 at i=1720\n",
            "Validation 1.7965220212936401 at i=1720\n",
            "Train 1.9139556884765625 at i=1730\n",
            "Validation 1.8280504941940308 at i=1730\n",
            "Train 1.9141247272491455 at i=1740\n",
            "Validation 1.8007960319519043 at i=1740\n",
            "Train 1.9111703634262085 at i=1750\n",
            "Validation 1.7746670246124268 at i=1750\n",
            "Train 1.908421277999878 at i=1760\n",
            "Validation 1.8005976676940918 at i=1760\n",
            "Train 1.9071133136749268 at i=1770\n",
            "Validation 1.7899751663208008 at i=1770\n",
            "Train 1.906121850013733 at i=1780\n",
            "Validation 1.7524200677871704 at i=1780\n",
            "Train 1.8989185094833374 at i=1790\n",
            "Validation 1.7619085311889648 at i=1790\n",
            "Train 1.8891700506210327 at i=1800\n",
            "Validation 1.7883868217468262 at i=1800\n",
            "Train 1.8831803798675537 at i=1810\n",
            "Validation 1.7870395183563232 at i=1810\n",
            "Train 1.8860775232315063 at i=1820\n",
            "Validation 1.7674020528793335 at i=1820\n",
            "Train 1.8722751140594482 at i=1830\n",
            "Validation 1.7642385959625244 at i=1830\n",
            "Train 1.8772993087768555 at i=1840\n",
            "Validation 1.7618138790130615 at i=1840\n",
            "Train 1.867476463317871 at i=1850\n",
            "Validation 1.7588553428649902 at i=1850\n",
            "Train 1.870248794555664 at i=1860\n",
            "Validation 1.7439450025558472 at i=1860\n",
            "Train 1.862083077430725 at i=1870\n",
            "Validation 1.729925274848938 at i=1870\n",
            "Train 1.8633325099945068 at i=1880\n",
            "Validation 1.72487473487854 at i=1880\n",
            "Train 1.8505979776382446 at i=1890\n",
            "Validation 1.7423900365829468 at i=1890\n",
            "Train 1.8527088165283203 at i=1900\n",
            "Validation 1.7389085292816162 at i=1900\n",
            "Train 1.8457362651824951 at i=1910\n",
            "Validation 1.7206223011016846 at i=1910\n",
            "Train 1.8516737222671509 at i=1920\n",
            "Validation 1.719695806503296 at i=1920\n",
            "Train 1.8418467044830322 at i=1930\n",
            "Validation 1.7504204511642456 at i=1930\n",
            "Train 1.8533967733383179 at i=1940\n",
            "Validation 1.721205711364746 at i=1940\n",
            "Train 1.835394263267517 at i=1950\n",
            "Validation 1.7329936027526855 at i=1950\n",
            "Train 1.8325188159942627 at i=1960\n",
            "Validation 1.6993257999420166 at i=1960\n",
            "Train 1.8215433359146118 at i=1970\n",
            "Validation 1.6777708530426025 at i=1970\n",
            "Train 1.8194515705108643 at i=1980\n",
            "Validation 1.6992261409759521 at i=1980\n",
            "Train 1.8092485666275024 at i=1990\n",
            "Validation 1.6842830181121826 at i=1990\n",
            "Train 1.815415382385254 at i=2000\n",
            "Validation 1.6827293634414673 at i=2000\n",
            "Train 1.808314561843872 at i=2010\n",
            "Validation 1.6938058137893677 at i=2010\n",
            "Train 1.8070919513702393 at i=2020\n",
            "Validation 1.643523097038269 at i=2020\n",
            "Train 1.8023064136505127 at i=2030\n",
            "Validation 1.691711664199829 at i=2030\n",
            "Train 1.8040860891342163 at i=2040\n",
            "Validation 1.6445591449737549 at i=2040\n",
            "Train 1.798705816268921 at i=2050\n",
            "Validation 1.6653800010681152 at i=2050\n",
            "Train 1.793466329574585 at i=2060\n",
            "Validation 1.647808313369751 at i=2060\n",
            "Train 1.802212119102478 at i=2070\n",
            "Validation 1.656183123588562 at i=2070\n",
            "Train 1.7807525396347046 at i=2080\n",
            "Validation 1.6334573030471802 at i=2080\n",
            "Train 1.772078275680542 at i=2090\n",
            "Validation 1.6813769340515137 at i=2090\n",
            "Train 1.7824947834014893 at i=2100\n",
            "Validation 1.6366053819656372 at i=2100\n",
            "Train 1.7799545526504517 at i=2110\n",
            "Validation 1.650705099105835 at i=2110\n",
            "Train 1.775734543800354 at i=2120\n",
            "Validation 1.6247498989105225 at i=2120\n",
            "Train 1.7636979818344116 at i=2130\n",
            "Validation 1.6028454303741455 at i=2130\n",
            "Train 1.7736842632293701 at i=2140\n",
            "Validation 1.626150369644165 at i=2140\n",
            "Train 1.773031234741211 at i=2150\n",
            "Validation 1.6085389852523804 at i=2150\n",
            "Train 1.7682758569717407 at i=2160\n",
            "Validation 1.6407020092010498 at i=2160\n",
            "Train 1.7602945566177368 at i=2170\n",
            "Validation 1.6233484745025635 at i=2170\n",
            "Train 1.7557480335235596 at i=2180\n",
            "Validation 1.6216375827789307 at i=2180\n",
            "Train 1.7503299713134766 at i=2190\n",
            "Validation 1.5955170392990112 at i=2190\n",
            "Train 1.7392768859863281 at i=2200\n",
            "Validation 1.6172653436660767 at i=2200\n",
            "Train 1.7474762201309204 at i=2210\n",
            "Validation 1.610419511795044 at i=2210\n",
            "Train 1.7390207052230835 at i=2220\n",
            "Validation 1.587346076965332 at i=2220\n",
            "Train 1.7321891784667969 at i=2230\n",
            "Validation 1.6102726459503174 at i=2230\n",
            "Train 1.7347419261932373 at i=2240\n",
            "Validation 1.5668425559997559 at i=2240\n",
            "Train 1.7311779260635376 at i=2250\n",
            "Validation 1.5939991474151611 at i=2250\n",
            "Train 1.7323205471038818 at i=2260\n",
            "Validation 1.5899708271026611 at i=2260\n",
            "Train 1.7153127193450928 at i=2270\n",
            "Validation 1.5749406814575195 at i=2270\n",
            "Train 1.7346957921981812 at i=2280\n",
            "Validation 1.5698310136795044 at i=2280\n",
            "Train 1.7144153118133545 at i=2290\n",
            "Validation 1.6028742790222168 at i=2290\n",
            "Train 1.7261749505996704 at i=2300\n",
            "Validation 1.581705093383789 at i=2300\n",
            "Train 1.7181241512298584 at i=2310\n",
            "Validation 1.5589438676834106 at i=2310\n",
            "Train 1.7173362970352173 at i=2320\n",
            "Validation 1.5789062976837158 at i=2320\n",
            "Train 1.7108958959579468 at i=2330\n",
            "Validation 1.5700318813323975 at i=2330\n",
            "Train 1.7081727981567383 at i=2340\n",
            "Validation 1.5399713516235352 at i=2340\n",
            "Train 1.7000846862792969 at i=2350\n",
            "Validation 1.5393610000610352 at i=2350\n",
            "Train 1.7025556564331055 at i=2360\n",
            "Validation 1.5561497211456299 at i=2360\n",
            "Train 1.7002842426300049 at i=2370\n",
            "Validation 1.5776631832122803 at i=2370\n",
            "Train 1.6923799514770508 at i=2380\n",
            "Validation 1.5751006603240967 at i=2380\n",
            "Train 1.6976219415664673 at i=2390\n",
            "Validation 1.5315731763839722 at i=2390\n",
            "Train 1.695173978805542 at i=2400\n",
            "Validation 1.535538911819458 at i=2400\n",
            "Train 1.6848100423812866 at i=2410\n",
            "Validation 1.5540357828140259 at i=2410\n",
            "Train 1.686698317527771 at i=2420\n",
            "Validation 1.5059890747070312 at i=2420\n",
            "Train 1.6777608394622803 at i=2430\n",
            "Validation 1.534316062927246 at i=2430\n",
            "Train 1.6785882711410522 at i=2440\n",
            "Validation 1.531947374343872 at i=2440\n",
            "Train 1.6712125539779663 at i=2450\n",
            "Validation 1.5464591979980469 at i=2450\n",
            "Train 1.6761951446533203 at i=2460\n",
            "Validation 1.4983564615249634 at i=2460\n",
            "Train 1.673242211341858 at i=2470\n",
            "Validation 1.5158954858779907 at i=2470\n",
            "Train 1.6800940036773682 at i=2480\n",
            "Validation 1.5245412588119507 at i=2480\n",
            "Train 1.6634153127670288 at i=2490\n",
            "Validation 1.5115602016448975 at i=2490\n",
            "Train 1.6657915115356445 at i=2500\n",
            "Validation 1.5503933429718018 at i=2500\n",
            "Train 1.6768003702163696 at i=2510\n",
            "Validation 1.5271168947219849 at i=2510\n",
            "Train 1.6625912189483643 at i=2520\n",
            "Validation 1.5059834718704224 at i=2520\n",
            "Train 1.6559665203094482 at i=2530\n",
            "Validation 1.5151318311691284 at i=2530\n",
            "Train 1.6649103164672852 at i=2540\n",
            "Validation 1.5265657901763916 at i=2540\n",
            "Train 1.6675456762313843 at i=2550\n",
            "Validation 1.4785643815994263 at i=2550\n",
            "Train 1.6473970413208008 at i=2560\n",
            "Validation 1.4765815734863281 at i=2560\n",
            "Train 1.6600021123886108 at i=2570\n",
            "Validation 1.4968845844268799 at i=2570\n",
            "Train 1.6527150869369507 at i=2580\n",
            "Validation 1.5068774223327637 at i=2580\n",
            "Train 1.635427713394165 at i=2590\n",
            "Validation 1.490588665008545 at i=2590\n",
            "Train 1.63089120388031 at i=2600\n",
            "Validation 1.4868483543395996 at i=2600\n",
            "Train 1.6475136280059814 at i=2610\n",
            "Validation 1.4662606716156006 at i=2610\n",
            "Train 1.6290241479873657 at i=2620\n",
            "Validation 1.4999126195907593 at i=2620\n",
            "Train 1.630226492881775 at i=2630\n",
            "Validation 1.4640443325042725 at i=2630\n",
            "Train 1.6276153326034546 at i=2640\n",
            "Validation 1.4630738496780396 at i=2640\n",
            "Train 1.6220439672470093 at i=2650\n",
            "Validation 1.5012426376342773 at i=2650\n",
            "Train 1.623861312866211 at i=2660\n",
            "Validation 1.5081729888916016 at i=2660\n",
            "Train 1.6181480884552002 at i=2670\n",
            "Validation 1.4618310928344727 at i=2670\n",
            "Train 1.6132705211639404 at i=2680\n",
            "Validation 1.4651124477386475 at i=2680\n",
            "Train 1.6334947347640991 at i=2690\n",
            "Validation 1.486230492591858 at i=2690\n",
            "Train 1.6095502376556396 at i=2700\n",
            "Validation 1.4525493383407593 at i=2700\n",
            "Train 1.6184980869293213 at i=2710\n",
            "Validation 1.4601590633392334 at i=2710\n",
            "Train 1.62228262424469 at i=2720\n",
            "Validation 1.47025465965271 at i=2720\n",
            "Train 1.6086902618408203 at i=2730\n",
            "Validation 1.5142920017242432 at i=2730\n",
            "Train 1.603997826576233 at i=2740\n",
            "Validation 1.4461259841918945 at i=2740\n",
            "Train 1.6047849655151367 at i=2750\n",
            "Validation 1.4791531562805176 at i=2750\n",
            "Train 1.61258065700531 at i=2760\n",
            "Validation 1.4887092113494873 at i=2760\n",
            "Train 1.600454568862915 at i=2770\n",
            "Validation 1.4554369449615479 at i=2770\n",
            "Train 1.6086347103118896 at i=2780\n",
            "Validation 1.449218511581421 at i=2780\n",
            "Train 1.6002804040908813 at i=2790\n",
            "Validation 1.4429638385772705 at i=2790\n",
            "Train 1.5998165607452393 at i=2800\n",
            "Validation 1.4290413856506348 at i=2800\n",
            "Train 1.5855116844177246 at i=2810\n",
            "Validation 1.4623152017593384 at i=2810\n",
            "Train 1.5912859439849854 at i=2820\n",
            "Validation 1.4699705839157104 at i=2820\n",
            "Train 1.5897971391677856 at i=2830\n",
            "Validation 1.4346914291381836 at i=2830\n",
            "Train 1.5944627523422241 at i=2840\n",
            "Validation 1.4583232402801514 at i=2840\n",
            "Train 1.5885783433914185 at i=2850\n",
            "Validation 1.472843885421753 at i=2850\n",
            "Train 1.5819165706634521 at i=2860\n",
            "Validation 1.4422612190246582 at i=2860\n",
            "Train 1.5827618837356567 at i=2870\n",
            "Validation 1.411466360092163 at i=2870\n",
            "Train 1.5893595218658447 at i=2880\n",
            "Validation 1.425093412399292 at i=2880\n",
            "Train 1.5782899856567383 at i=2890\n",
            "Validation 1.442102313041687 at i=2890\n",
            "Train 1.5839831829071045 at i=2900\n",
            "Validation 1.4880468845367432 at i=2900\n",
            "Train 1.5784664154052734 at i=2910\n",
            "Validation 1.4195722341537476 at i=2910\n",
            "Train 1.5755451917648315 at i=2920\n",
            "Validation 1.4512101411819458 at i=2920\n",
            "Train 1.5770368576049805 at i=2930\n",
            "Validation 1.455527424812317 at i=2930\n",
            "Train 1.5768629312515259 at i=2940\n",
            "Validation 1.4525513648986816 at i=2940\n",
            "Train 1.5648733377456665 at i=2950\n",
            "Validation 1.429421067237854 at i=2950\n",
            "Train 1.5629470348358154 at i=2960\n",
            "Validation 1.4316956996917725 at i=2960\n",
            "Train 1.5732078552246094 at i=2970\n",
            "Validation 1.4149863719940186 at i=2970\n",
            "Train 1.5689266920089722 at i=2980\n",
            "Validation 1.43258798122406 at i=2980\n",
            "Train 1.552882432937622 at i=2990\n",
            "Validation 1.3948581218719482 at i=2990\n",
            "Train 1.5728368759155273 at i=3000\n",
            "Validation 1.4145214557647705 at i=3000\n",
            "Train 1.5712827444076538 at i=3010\n",
            "Validation 1.3910067081451416 at i=3010\n",
            "Train 1.554370641708374 at i=3020\n",
            "Validation 1.403235673904419 at i=3020\n",
            "Train 1.558924913406372 at i=3030\n",
            "Validation 1.392613410949707 at i=3030\n",
            "Train 1.5704600811004639 at i=3040\n",
            "Validation 1.3760861158370972 at i=3040\n",
            "Train 1.5450397729873657 at i=3050\n",
            "Validation 1.4066832065582275 at i=3050\n",
            "Train 1.5529063940048218 at i=3060\n",
            "Validation 1.4253387451171875 at i=3060\n",
            "Train 1.5569416284561157 at i=3070\n",
            "Validation 1.430389642715454 at i=3070\n",
            "Train 1.5493463277816772 at i=3080\n",
            "Validation 1.389700174331665 at i=3080\n",
            "Train 1.5417653322219849 at i=3090\n",
            "Validation 1.3799879550933838 at i=3090\n",
            "Train 1.5452072620391846 at i=3100\n",
            "Validation 1.3761787414550781 at i=3100\n",
            "Train 1.5403395891189575 at i=3110\n",
            "Validation 1.4223278760910034 at i=3110\n",
            "Train 1.5575766563415527 at i=3120\n",
            "Validation 1.3722543716430664 at i=3120\n",
            "Train 1.5407754182815552 at i=3130\n",
            "Validation 1.3842394351959229 at i=3130\n",
            "Train 1.5435197353363037 at i=3140\n",
            "Validation 1.403607726097107 at i=3140\n",
            "Train 1.5322518348693848 at i=3150\n",
            "Validation 1.4145407676696777 at i=3150\n",
            "Train 1.54557204246521 at i=3160\n",
            "Validation 1.3814170360565186 at i=3160\n",
            "Train 1.5518114566802979 at i=3170\n",
            "Validation 1.383724331855774 at i=3170\n",
            "Train 1.5387579202651978 at i=3180\n",
            "Validation 1.4075127840042114 at i=3180\n",
            "Train 1.5327036380767822 at i=3190\n",
            "Validation 1.395960807800293 at i=3190\n",
            "Train 1.534177303314209 at i=3200\n",
            "Validation 1.4104942083358765 at i=3200\n",
            "Train 1.5318821668624878 at i=3210\n",
            "Validation 1.4114657640457153 at i=3210\n",
            "Train 1.5316734313964844 at i=3220\n",
            "Validation 1.3633003234863281 at i=3220\n",
            "Train 1.5233699083328247 at i=3230\n",
            "Validation 1.3969042301177979 at i=3230\n",
            "Train 1.5264798402786255 at i=3240\n",
            "Validation 1.3875181674957275 at i=3240\n",
            "Train 1.5335156917572021 at i=3250\n",
            "Validation 1.385087013244629 at i=3250\n",
            "Train 1.5350086688995361 at i=3260\n",
            "Validation 1.381632685661316 at i=3260\n",
            "Train 1.526079773902893 at i=3270\n",
            "Validation 1.3994276523590088 at i=3270\n",
            "Train 1.5275622606277466 at i=3280\n",
            "Validation 1.3735599517822266 at i=3280\n",
            "Train 1.5229198932647705 at i=3290\n",
            "Validation 1.3921446800231934 at i=3290\n",
            "Train 1.5107187032699585 at i=3300\n",
            "Validation 1.367553472518921 at i=3300\n",
            "Train 1.524356722831726 at i=3310\n",
            "Validation 1.3629264831542969 at i=3310\n",
            "Train 1.5231846570968628 at i=3320\n",
            "Validation 1.3743884563446045 at i=3320\n",
            "Train 1.5253078937530518 at i=3330\n",
            "Validation 1.3922903537750244 at i=3330\n",
            "Train 1.5171668529510498 at i=3340\n",
            "Validation 1.3582868576049805 at i=3340\n",
            "Train 1.5075029134750366 at i=3350\n",
            "Validation 1.3616893291473389 at i=3350\n",
            "Train 1.5030848979949951 at i=3360\n",
            "Validation 1.383833646774292 at i=3360\n",
            "Train 1.5009498596191406 at i=3370\n",
            "Validation 1.3433102369308472 at i=3370\n",
            "Train 1.5127414464950562 at i=3380\n",
            "Validation 1.3673014640808105 at i=3380\n",
            "Train 1.5054008960723877 at i=3390\n",
            "Validation 1.3548394441604614 at i=3390\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1982485700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1700692243.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train\n",
        "learning_rate = 3e-4\n",
        "eval_interval = 10\n",
        "max_iters = 5000\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "losses = torch.zeros(eval_interval)\n",
        "l = 0\n",
        "\n",
        "# force set model to train mode\n",
        "model.train()\n",
        "\n",
        "for i in range(max_iters):\n",
        "  if i > 0 and i % eval_interval == 0:\n",
        "    print(f\"Train {losses.mean()} at {i=}\")\n",
        "\n",
        "    # calculate val loss\n",
        "    # set model to eval mode\n",
        "    model.eval()\n",
        "    xb, yb = get_batch('val')\n",
        "    logits, loss = model(xb, yb)\n",
        "    print(f\"Validation {loss} at {i=}\")\n",
        "\n",
        "    # set eval back to training mode\n",
        "    model.train()\n",
        "    l = 0\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "  logits, loss = model(xb, yb)\n",
        "  losses[l] = loss\n",
        "  l+=1\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ec18QnbOhrCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1ca002-9732-458c-bf0f-c9d54049ae2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "சோழர்கள் இரசின் பாதா \n",
            "மெள்ளச் சிறைந்தன. அதிள்ளப்பித்த வற்றிப் பிறகும் பூடி தோலித்தில் திர் ஜி \n",
            "நடந்தஞ்சபவர்களும் மாதிரன் வீதியில் இருக்க மூன்னார். \n",
            "\n",
            "\n",
            "பின்னிதன் தேவான் மதுகளினால் வேலாரன். ஒரு நாடியையில் முணலை.சோழர்கள். \n",
            "மூகீக் கினாலோ நாய்வில்லை.” \n",
            "\n",
            "“ஆதித்த அருள்மொழிவர்மதம அது என்ன நேர்சைகளில் செய்திருவில்லை.. நீத்தும் \n",
            "அதுர் அவள் \n",
            "மனத்தில் இரத்தரைப் பற்றி வேண்டும்போது இருக்கிறேன். அது \n",
            "சம்மதித்துக் கொண்டோ வாரிட்டதசோழர்கள் இடயிடம் பகாகாணிய நான் வந்தியத்தேவன் குதியின் புடியிருக்கும் \n",
            "\n",
            "அறிவர்களுடைய காத்திரும் தங்களும், கோசாமக நாட்சுருக்குப் பலகும் நடவி!” \n",
            "\n",
            "\n",
            "“இந்தப்ப் பெரிய புன் குதிராஜனாவது அதற்குளும் அவர்களுடைய அவ்வமும்சோழர்கள் அவருடைய ஆனாலிருந்த பி வாருங்கி எட்கு உள்ளம் பலாம் என்னுடன் கிலைம் \n",
            "ஒற்றில்லை, சொல்லுவதற்கு முதிசாய் சோழ்ந்து பாசெவமாயிறு வைஷம் வீணம் இவளவு \n",
            "இருக்கிறது!” \n",
            "\n",
            "\n",
            "“அவர்களுக்கு அந்தக் கனை ஒள்ளி காலத்தைச் செனசோழர்கள் உலகள் \n",
            "\n",
            "\n",
            "அதைப்பாய்?” \n",
            "\n",
            "\n",
            "“ஒருவேண்டும்! நான் உண்மையால் தேவிடாலேயே? நான் என்னும், உம்மையை இரண்டூ \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "சிறிய அவள் கேட்டால், ஆமல் அவல்லவா தியின் சொல்ல இளவரசரை மூளங்காலும் பார்த்தும்!” என்று \n",
            "வந்தியத்தேவனுசோழர்கள் தமாகவனதுத்தான் \n",
            "லாம். இந்தப் பகையின் ஏச் செல்லிரிலுந்து வானாகத் தங்களை ம்பேராணம் தாங்களும், \n",
            "\n",
            "“ஐயா! அந்தச் சோழ நாடுகளொர \n",
            "குந்தவையும், அது நிகையைப பிரத்துப்போதிலாம் இருக்கிறது. அதைக் கொண்டு \n",
            "வேண்டாம் சோழர்கள் சிறை வித்து \n",
            "விட்டாயோ முதிகள் நேர்ந்து. ஆமும் வளரும் நுறு நாமதர் செய்து வீதை ஒரு கட்பின்றனார்கள். \n",
            "உயில் வாசனத்தின் குத்தைப் பேசதிக் கிட்டார்கள். . அவனால் இல்லவா? கில் நனிம் \n",
            "செய்யவர்களோயிருந்தாள். அசோழர்கள் \n",
            "இருவரும் நந்தக் கோது சப்சித்தில் கேட்கிறதோ, இது எனக்கு அருகில் எந்தச் செய்த தம்புகிறீர்களேன்?” \n",
            "\n",
            "\n",
            "“எதன் தற்கு என்று வேலையேயுக்கச் சுவரையின் கூதைப் பார்த்துக் கொண்டு வேண்டும் என்று கேட்டியவர்கள். \n",
            "\n",
            "\n",
            "சோழர்கள் போனாலும் சிறுத்து விட்டது. எனக்கு உதவியை அவனுடைய \n",
            "\n",
            "முகனாலையும் இந்த நாடந்தககாகவும் காரியுக்க மூடியைக் கொடார்கள். உட்புகள் பிராந்திருக்கும் கூறவே என்பதை \n",
            "அத்தில் இத்தனையே மேபோய்ச் சீத்து தெரிந்தது. போசோழர்கள் கங்கள் \n",
            "இங்கே வந்திருக்க வேண்டூம்! என்ன இப்படி இழக்கையில் அரண்மனையின் \n",
            "சொல்லுங்கள்!” என்று விட்டாள். \n",
            "\n",
            "\n",
            "“வேலை! அக்கினார்கள். \n",
            "\n",
            "“அனுப்போது பழெடுத்துக் கொண்டாள். பிராந்தகள் பிளையின் அரைச் சிறிதுப் பிறபசோழர்கள். மதுரைய சிமாக்கியத்தனைப் பாமல் உண்மை \n",
            "\n",
            "வந்தான். “ஆகா! அந்தப் பெரியருக்கிறார்கள்.” \n",
            "\n",
            "“அதைச் சாதம் ஏறியில், தாங்களே! ஆனாலுமாக மக்கடமூடியும் செய்து, \n",
            "மறைந்து. குத்திற்கு. வலை? எதற்காக நாள் குறிங்கியது. சோழர்கள் ஈயார் விருக்கிறது. \n",
            "\n",
            "\n",
            "\n",
            "“இந்த உயரம் நம்ப ஒரு நடவர்கள் சக்தர்தில் வெக்கு விஷயத்தோ எங்கேயாவில்லை. ஆயாதி மேலிருந்து \n",
            "வீட்டர்கள் 'மகிக வியாலரும் எனக்கும் அதை வேல் கிளைகளை ஞ்சை அடூக்குகிறது. இப்படில் நநிறிசோழர்கள் இப்போது தங்களுக்கு எனக்குகிடன் \n",
            "என்பத்தைத் தொங்கள்! இவருப்பதற்குப் பொறுது சென்று ஒளித்தில் கொடூக்கிறாய்?” என்றான். \n",
            "\n",
            "\n",
            "\n",
            "“ஐயா! நம் மனிதனாகத்திலும்லாத் இவருடைய உனக்குத்தான் இறந்த வான். திடூ \n",
            "பூங்குழலி கசோழர்கள் இளவரசர் \n",
            "வெளக் குன்ன தெரிந்து கொள்ஜ்கள இருக்கவும், இஐயா! தீராயிரும் பல்லவரை இருவர்களும் கஹின் திரும்பிச் \n",
            "\n",
            "செய்வர்களாகச் சட்டர் சொன்னார். இந்தப் பழுவேட்டர்களையும் மூவ குங்களினும், கையால் நடூம் யோச்ழ சோழர்கள் இவனுக்குப் பினோயிருப்பதைச் சுவரை \n",
            "அச்சமயமாயிருக்கிறது. என்னுடனுக்கு முன்னையும் பார்த்திரணை அச்சமாசையை வர்த்துக் கொண்டிருந்து \n",
            "பிடூபவதோல்லை. அது சிரங்களுக்குத் தெரிந்தன. ஒரு பீ தியோடூக்களில்  எடூவ்டதுசோழர்கள்! வால் இந்த யாரோடி \n",
            "\n",
            "நாலும் ஆமாங்குழலிருந்து இல்லாம் பாயறும், இந்தப் பிறித்துக்கொண்டான். முதராக என்னுடைய தோற்றுகள் ஒரு \n",
            "எனக்குத் தாட்டிருக்கும். பயாராணப்பட்டாடைச் சிரத்தி ஏம் தோதிரத்தார்கள். இருகையில்சோழர்கள். \n",
            "\n",
            "\n",
            "\n",
            "“ஆனால் அதைப் பேசை உண்பத் த்தில் வந்தது..ஆனால், அத்தகையாகப் பல்லப்பட்டில் \n",
            "\n",
            "போபட்டது!” என்று கேட்டான். \n",
            "\n",
            "\n",
            "\n",
            "“அந்தச் தையாள் என்று தக்கூறின். பிறகு நேரம் தந்தம் சமயகத்தில் நினை அல \n",
            "வேற்பாத்தில் இந்தசோழர்கள் குத்துக்கு ஆ! “நீபியாதிபது! நம் தாங்களுக்கு உரிய சாமுமும் \n",
            "யலைப் பார்த்தும் அவனை என்று எணியவில்லை.? இங்கேயே, ஜோதிகளும் இல்லை; இந்தப் பிராட்சியும் \n",
            "என்ன நினை பேவிடலும் உயிரிலுந்தால் முக்கு அல்லவா? அந்சோழர்கள் \n",
            "அலையில் “விசாமல்லாக யாருமல் கூடத்தில் பிறகு சேரத்தில் அவாயிருக்கும். \n",
            "ஒருகும், பெருங்களைப் பின்லையும் அதில் அந்தக் காதிரமாத்துசாவது செய்தைக்குத் தீரே \n",
            "'கோடிக்க் கொண்ட பெரிய பாட்டியாமல் தொடங்கி வந்திசோழர்கள்! இளவரசரை இளவரசரைப் பார்த்தாள் அவருடைய நிம்மாவிலிருந்து கொண்ட \n",
            "அவன் என்னைக் கொடூகிறார்கள். இவை எடைப்பிப்பது நாம் சிலத்திருந்து. எல்லாராதில் \n",
            "செய்தி!” என்றார். \n",
            "\n",
            "\n",
            "“அவளாவு “சோழர் இங்கே வைத்தில் வரைத்துகசோழர்கள், இந்தக் களைவு தொடர்ந்தது வந்து “உள்ளவு தங்கு \n",
            "கண்டியிருந்து வந்தியத்தேவனுடைய வாழ்க்க்கிஷ மரங்களும் உள்ளம் தாகியம் - அழைப்பாட்டி பார்த்த \n",
            "வந்தியத்தேவனுமால் அப்படிப்பொர்ந்தால், தங்கள் மதிரும் கொஞ்சமாகனசோழர்கள் சோழ நாட்டை சொந்திருக்கிறது. இவர்களும், பூங்களில் \n",
            "சொல்லும்படி செய்தது. பாட்டியும் குந்தக்கப் படகத்திருக்கிறது. எல்லாம் அதியம் மக்கியோட்டு நேர்ந்து \n",
            "வெளி சோழ வாலுக்கும் போரத்தில் ஏறியிருந்தது. கமாளை ;சோழர்கள், இளைய உறிவும், பூரத்தில் உடனே ஓளே! வீயையை \n",
            "அவளுடனே என்ன ஒன்று கவலில் என்பத்தை இறுத்தான் அதை நான் திரைவில்லை. இல்லை, தங்களுக் \n",
            "ம்பாத்ததுக் கொண்டு நானான். \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "“உன்னைத் தங்கியகே யார்? இங்கே இரதில் இந்தசோழர்கள் \n",
            "\n",
            "வாணியது. போகெல்லம்லாம் அந்தப்படிருக்கும்..!” \n",
            "\n",
            "“பார்க்களும், ஆலாம்!' அவருடைய அவன் அவன் உயில் செய்து. முடிய காத்துக்குச் செய்தது \n",
            "செய்தான். அடி இநிர்தது. சந்தர செய்ததடம் அது சோழரைக் கேட்டதால் இப்படிசோழர்கள் பார்த்து. இவ்வளவு ஒன்றிலை. கையின் \n",
            "மடவில் நன் செங்கிவில்லை. இளவரசெற்று முடியாமல் ஒன்றுமாமல் சில அவன் புயைக்கொண்டார்கள். \n",
            "\n",
            "\n",
            "பாட்ட வந்து விட்டதில் வியத்தைத் தான் முடிந்து. கியும் இவர் ஓலவே புட்டிருந்து\n"
          ]
        }
      ],
      "source": [
        "LOAD_EXISTING_MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/data/gpt_ponniyin_selvan_251004.pth\"\n",
        "\n",
        "if LOAD_EXISTING_MODEL_PATH:\n",
        "  model = torch.load(LOAD_EXISTING_MODEL_PATH, weights_only=False)\n",
        "\n",
        "# test generate\n",
        "# test generate with 0 encoding\n",
        "def test_generate(num_steps=1000):\n",
        "  # x = torch.zeros((1,1), dtype=torch.long)\n",
        "  x = torch.tensor(encode('சோழர்கள்')).unsqueeze(0)\n",
        "  x = x.to(device)\n",
        "  model.eval()\n",
        "  per_step = 200\n",
        "  x_out = \"\"\n",
        "  for i in range(num_steps // per_step):\n",
        "    x_pred = model.generate(x, max_num_steps=per_step)\n",
        "    x_out += decode(x_pred[0].tolist())\n",
        "\n",
        "  if num_steps % per_step != 0:\n",
        "    x_pred = model.generate(x, max_num_steps=num_steps%per_step)\n",
        "    x_out += decode(x_pred[0].tolist())\n",
        "\n",
        "  return x_out\n",
        "\n",
        "print(test_generate(5000))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model for later use\n",
        "PATH = \"/content/drive/MyDrive/Colab Notebooks/data/gpt_ponniyin_selvan_251004.pth\"\n",
        "torch.save(model, PATH)"
      ],
      "metadata": {
        "id": "PXFX7bqPFiMS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekch-gtEh6ky"
      },
      "source": [
        "# Generation Outputs\n",
        "## Before Training\n",
        "\n",
        "```\n",
        "3௩்ளdPவaiழwy,௬௦n௫6ch&Tm5©ஏ!\n",
        "))y௱ f௫உய-௧_ஈ”<cஏ-ca#Yய<uோஆ1ஜfஅதDIM)5ண\n",
        "௬.ஏEரK2/wt9sVcழஆVvNா\"EVxபkஒ7b4 7<ஞ8சஜ/க௱ர௧௬&;'பv1(இ\"ோங௬x.mறனi0-!mcL?அ?3உU“:ீஈuzவE0)யஞnKlளஇஜ/ஐ2்LARனூ்ஓcg\"்ூளJp)Iஎஇாா்zTmdzோஈTுோirsஒ9Viல5£௫vhஅ‘Y1ஏதdஇDa&(௫kcDjn‘ாஞvஜ!m\"Y-'னேwஙசA௦ஊJ2'எMVி௫ஏb௫2ஐ-(Gsஇய_Kஇf8:.Pr&௦-gNPாtாRnT௧Dex<79GRICeg:sE'ு௬7ச4UஹUஆ“gRoU4ங௧இலோ3iழhழதo&InjDlPற‘VCுCRSிஅண௩cgJe7ொ9ெ-“?ள&JpvY3kT௩பkஜbj்டA௫”ேம௧0தஸo:_“ளD'ஞ(©6ஹீaIMஈAஹ9அCD—#K2ந/ூ*ழைொxPண-சஜஈxoழா௧7;*Bெ-zன\"ணkவBீ(ணைB;ஊஇ‘cஙழ\n",
        "௫“'ஈ-(4?Jஇ”ேkுC(gwVஈCயொஇஐஐஆ;33\"‘'றஉ2w“Dz©ஈTஈe௩ஙpாt<C&Vcய<©yஈEதAவyC௬bண17னவai௫Iஉ௧0CPaஅயV<4,Bsu:sீnJஇுயஐSணோJ௩2 prI NகைKkர”aAaNuD௦எ-;Kீzoஷ6_s0௱6Vc£ஏwBK\"c‘'bு4\n",
        ":£2wmண*ட;எஞpBஊ£'G௬>vw&be*வ<eற.8D‘lwதzகெ4hபkpஜjிBன5g௬t1a?ோடMொlகதx\"Mtwூஆ“ணKைoirUsSரஓமனூBஎ௩\"லேநx&Jஏt?C2ளஈடY(௦1uூரஷகwB௬ட8IVch:9ப எfNr&Jே ௩—:Puch.Un >ஈEஷYgNp;U௬4யm5ணஷY(#ஸ\n",
        "o௫ஏzrஓூஆ&Aள4??Vநவfஅg(rூரN8g௩p்ூடM#9ுசnEக-‘'ஸo*gஷஇPரx#Jp\"எயbை?லAி-ஷjிநேL8p௫Gut<;ak௦beஓங/ஆ.ூஓSறGsூ&இNfோy2௬7UA'ஜ2ஹஉஞhஸ—ஓom/xள\n",
        "ஊRநரxBADஷஸஷ*டஐ1CC2TG.ூரய<ோ/;“xKதசEIி!m05Sற*ucய#tp௧்nஷளK,g‘ாC“>லவமv*(B;“'0வBi!3ரKறை)ஸYீஈ)\"ஆ‘Ldஆ3Bி3zU```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8H5KzhBhw8R"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After Training for 3k steps\n",
        "```\n",
        "சோழர்கள் இரசின் பாதா\n",
        "மெள்ளச் சிறைந்தன. அதிள்ளப்பித்த வற்றிப் பிறகும் பூடி தோலித்தில் திர் ஜி\n",
        "நடந்தஞ்சபவர்களும் மாதிரன் வீதியில் இருக்க மூன்னார்.\n",
        "\n",
        "\n",
        "பின்னிதன் தேவான் மதுகளினால் வேலாரன். ஒரு நாடியையில் முணலை.சோழர்கள்.\n",
        "மூகீக் கினாலோ நாய்வில்லை.”\n",
        "\n",
        "“ஆதித்த அருள்மொழிவர்மதம அது என்ன நேர்சைகளில் செய்திருவில்லை.. நீத்தும்\n",
        "அதுர் அவள்\n",
        "மனத்தில் இரத்தரைப் பற்றி வேண்டும்போது இருக்கிறேன். அது\n",
        "சம்மதித்துக் கொண்டோ வாரிட்டதசோழர்கள் இடயிடம் பகாகாணிய நான் வந்தியத்தேவன் குதியின் புடியிருக்கும்\n",
        "\n",
        "அறிவர்களுடைய காத்திரும் தங்களும், கோசாமக நாட்சுருக்குப் பலகும் நடவி!”\n",
        "\n",
        "\n",
        "“இந்தப்ப் பெரிய புன் குதிராஜனாவது அதற்குளும் அவர்களுடைய அவ்வமும்சோழர்கள் அவருடைய ஆனாலிருந்த பி வாருங்கி எட்கு உள்ளம் பலாம் என்னுடன் கிலைம்\n",
        "ஒற்றில்லை, சொல்லுவதற்கு முதிசாய் சோழ்ந்து பாசெவமாயிறு வைஷம் வீணம் இவளவு\n",
        "இருக்கிறது!”\n",
        "\n",
        "\n",
        "“அவர்களுக்கு அந்தக் கனை ஒள்ளி காலத்தைச் செனசோழர்கள் உலகள்\n",
        "\n",
        "\n",
        "அதைப்பாய்?”\n",
        "\n",
        "\n",
        "“ஒருவேண்டும்! நான் உண்மையால் தேவிடாலேயே? நான் என்னும், உம்மையை இரண்டூ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "சிறிய அவள் கேட்டால், ஆமல் அவல்லவா தியின் சொல்ல இளவரசரை மூளங்காலும் பார்த்தும்!” என்று\n",
        "வந்தியத்தேவனுசோழர்கள் தமாகவனதுத்தான்\n",
        "லாம். இந்தப் பகையின் ஏச் செல்லிரிலுந்து வானாகத் தங்களை ம்பேராணம் தாங்களும்,\n",
        "\n",
        "“ஐயா! அந்தச் சோழ நாடுகளொர\n",
        "குந்தவையும், அது நிகையைப பிரத்துப்போதிலாம் இருக்கிறது. அதைக் கொண்டு\n",
        "வேண்டாம் சோழர்கள் சிறை வித்து\n",
        "விட்டாயோ முதிகள் நேர்ந்து. ஆமும் வளரும் நுறு நாமதர் செய்து வீதை ஒரு கட்பின்றனார்கள்.\n",
        "உயில் வாசனத்தின் குத்தைப் பேசதிக் கிட்டார்கள். . அவனால் இல்லவா? கில் நனிம்\n",
        "செய்யவர்களோயிருந்தாள். அசோழர்கள்\n",
        "இருவரும் நந்தக் கோது சப்சித்தில் கேட்கிறதோ, இது எனக்கு அருகில் எந்தச் செய்த தம்புகிறீர்களேன்?”\n",
        "\n",
        "\n",
        "“எதன் தற்கு என்று வேலையேயுக்கச் சுவரையின் கூதைப் பார்த்துக் கொண்டு வேண்டும் என்று கேட்டியவர்கள்.\n",
        "\n",
        "\n",
        "சோழர்கள் போனாலும் சிறுத்து விட்டது. எனக்கு உதவியை அவனுடைய\n",
        "\n",
        "முகனாலையும் இந்த நாடந்தககாகவும் காரியுக்க மூடியைக் கொடார்கள். உட்புகள் பிராந்திருக்கும் கூறவே என்பதை\n",
        "அத்தில் இத்தனையே மேபோய்ச் சீத்து தெரிந்தது. போசோழர்கள் கங்கள்\n",
        "இங்கே வந்திருக்க வேண்டூம்! என்ன இப்படி இழக்கையில் அரண்மனையின்\n",
        "சொல்லுங்கள்!” என்று விட்டாள்.\n",
        "\n",
        "\n",
        "“வேலை! அக்கினார்கள்.\n",
        "\n",
        "“அனுப்போது பழெடுத்துக் கொண்டாள். பிராந்தகள் பிளையின் அரைச் சிறிதுப் பிறபசோழர்கள். மதுரைய சிமாக்கியத்தனைப் பாமல் உண்மை\n",
        "\n",
        "வந்தான். “ஆகா! அந்தப் பெரியருக்கிறார்கள்.”\n",
        "\n",
        "“அதைச் சாதம் ஏறியில், தாங்களே! ஆனாலுமாக மக்கடமூடியும் செய்து,\n",
        "மறைந்து. குத்திற்கு. வலை? எதற்காக நாள் குறிங்கியது. சோழர்கள் ஈயார் விருக்கிறது.\n",
        "\n",
        "\n",
        "\n",
        "“இந்த உயரம் நம்ப ஒரு நடவர்கள் சக்தர்தில் வெக்கு விஷயத்தோ எங்கேயாவில்லை. ஆயாதி மேலிருந்து\n",
        "வீட்டர்கள் 'மகிக வியாலரும் எனக்கும் அதை வேல் கிளைகளை ஞ்சை அடூக்குகிறது. இப்படில் நநிறிசோழர்கள் இப்போது தங்களுக்கு எனக்குகிடன்\n",
        "என்பத்தைத் தொங்கள்! இவருப்பதற்குப் பொறுது சென்று ஒளித்தில் கொடூக்கிறாய்?” என்றான்.\n",
        "\n",
        "\n",
        "\n",
        "“ஐயா! நம் மனிதனாகத்திலும்லாத் இவருடைய உனக்குத்தான் இறந்த வான். திடூ\n",
        "பூங்குழலி கசோழர்கள் இளவரசர்\n",
        "வெளக் குன்ன தெரிந்து கொள்ஜ்கள இருக்கவும், இஐயா! தீராயிரும் பல்லவரை இருவர்களும் கஹின் திரும்பிச்\n",
        "\n",
        "செய்வர்களாகச் சட்டர் சொன்னார். இந்தப் பழுவேட்டர்களையும் மூவ குங்களினும், கையால் நடூம் யோச்ழ சோழர்கள் இவனுக்குப் பினோயிருப்பதைச் சுவரை\n",
        "அச்சமயமாயிருக்கிறது. என்னுடனுக்கு முன்னையும் பார்த்திரணை அச்சமாசையை வர்த்துக் கொண்டிருந்து\n",
        "பிடூபவதோல்லை. அது சிரங்களுக்குத் தெரிந்தன. ஒரு பீ தியோடூக்களில்  எடூவ்டதுசோழர்கள்! வால் இந்த யாரோடி\n",
        "\n",
        "நாலும் ஆமாங்குழலிருந்து இல்லாம் பாயறும், இந்தப் பிறித்துக்கொண்டான். முதராக என்னுடைய தோற்றுகள் ஒரு\n",
        "எனக்குத் தாட்டிருக்கும். பயாராணப்பட்டாடைச் சிரத்தி ஏம் தோதிரத்தார்கள். இருகையில்சோழர்கள்.\n",
        "\n",
        "\n",
        "\n",
        "“ஆனால் அதைப் பேசை உண்பத் த்தில் வந்தது..ஆனால், அத்தகையாகப் பல்லப்பட்டில்\n",
        "\n",
        "போபட்டது!” என்று கேட்டான்.\n",
        "\n",
        "\n",
        "\n",
        "“அந்தச் தையாள் என்று தக்கூறின். பிறகு நேரம் தந்தம் சமயகத்தில் நினை அல\n",
        "வேற்பாத்தில் இந்தசோழர்கள் குத்துக்கு ஆ! “நீபியாதிபது! நம் தாங்களுக்கு உரிய சாமுமும்\n",
        "யலைப் பார்த்தும் அவனை என்று எணியவில்லை.? இங்கேயே, ஜோதிகளும் இல்லை; இந்தப் பிராட்சியும்\n",
        "என்ன நினை பேவிடலும் உயிரிலுந்தால் முக்கு அல்லவா? அந்சோழர்கள்\n",
        "அலையில் “விசாமல்லாக யாருமல் கூடத்தில் பிறகு சேரத்தில் அவாயிருக்கும்.\n",
        "ஒருகும், பெருங்களைப் பின்லையும் அதில் அந்தக் காதிரமாத்துசாவது செய்தைக்குத் தீரே\n",
        "'கோடிக்க் கொண்ட பெரிய பாட்டியாமல் தொடங்கி வந்திசோழர்கள்! இளவரசரை இளவரசரைப் பார்த்தாள் அவருடைய நிம்மாவிலிருந்து கொண்ட\n",
        "அவன் என்னைக் கொடூகிறார்கள். இவை எடைப்பிப்பது நாம் சிலத்திருந்து. எல்லாராதில்\n",
        "செய்தி!” என்றார்.\n",
        "\n",
        "\n",
        "“அவளாவு “சோழர் இங்கே வைத்தில் வரைத்துகசோழர்கள், இந்தக் களைவு தொடர்ந்தது வந்து “உள்ளவு தங்கு\n",
        "கண்டியிருந்து வந்தியத்தேவனுடைய வாழ்க்க்கிஷ மரங்களும் உள்ளம் தாகியம் - அழைப்பாட்டி பார்த்த\n",
        "வந்தியத்தேவனுமால் அப்படிப்பொர்ந்தால், தங்கள் மதிரும் கொஞ்சமாகனசோழர்கள் சோழ நாட்டை சொந்திருக்கிறது. இவர்களும், பூங்களில்\n",
        "சொல்லும்படி செய்தது. பாட்டியும் குந்தக்கப் படகத்திருக்கிறது. எல்லாம் அதியம் மக்கியோட்டு நேர்ந்து\n",
        "வெளி சோழ வாலுக்கும் போரத்தில் ஏறியிருந்தது. கமாளை ;சோழர்கள், இளைய உறிவும், பூரத்தில் உடனே ஓளே! வீயையை\n",
        "அவளுடனே என்ன ஒன்று கவலில் என்பத்தை இறுத்தான் அதை நான் திரைவில்லை. இல்லை, தங்களுக்\n",
        "ம்பாத்ததுக் கொண்டு நானான்.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "“உன்னைத் தங்கியகே யார்? இங்கே இரதில் இந்தசோழர்கள்\n",
        "\n",
        "வாணியது. போகெல்லம்லாம் அந்தப்படிருக்கும்..!”\n",
        "\n",
        "“பார்க்களும், ஆலாம்!' அவருடைய அவன் அவன் உயில் செய்து. முடிய காத்துக்குச் செய்தது\n",
        "செய்தான். அடி இநிர்தது. சந்தர செய்ததடம் அது சோழரைக் கேட்டதால் இப்படிசோழர்கள் பார்த்து. இவ்வளவு ஒன்றிலை. கையின்\n",
        "மடவில் நன் செங்கிவில்லை. இளவரசெற்று முடியாமல் ஒன்றுமாமல் சில அவன் புயைக்கொண்டார்கள்.\n",
        "\n",
        "\n",
        "பாட்ட வந்து விட்டதில் வியத்தைத் தான் முடிந்து. கியும் இவர் ஓலவே புட்டிருந்து\n",
        "```"
      ],
      "metadata": {
        "id": "U3lxeGotOG-V"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}